# problem 1 - additional parsing defintions 

import kep.ini as ini
from kep.reader.parsing_defintions import ParsingDefinition
main_def = ParsingDefinition(path=ini.get_mainspec_filepath())
pathlist = ini.get_additional_filepaths()
more_def = [ParsingDefinition(path) for path in pathlist]

print("Main parsing definition:\n", groups)
groups = [main_def]

print("""PROBLEM 1: 

    We have several additional parsing definitions which apply to
    segments of csv file (from start line to end line).
    
    We can import these defintions as in *more_def* , but they are never
    used in containers.py when parsing table headers.

    When dealing with segments of csv file, only a single parsing definition 
    aplies to a segment, it is either main spec or some additional spec.

    For previous implementatoin see SegmentState class in 
    https://github.com/epogrebnyak/data-rosstat-kep/blob/master/kep/reader/reader.py#L29-L85
    
        SegmentState(default_spec, other_specs).assign_segments(heads)

    was used to assign parsing definition to each segment.
    
    Maybe in containers.py we can also walk by table headers and assing a parsing
    definition to each table. 
    
    Block().textrows
           .datarows
           .parsing_defintion
           
    Block().yield_datapoints()       
           

    
    
""")
while more_def:
    p = more_def.pop()
    cur_group = [p]
    for d in more_def:
        if d.has_same_scope(p):
            cur_group.append(d)
            more_def.remove(d)
    print()
    print (cur_group)               
    groups.append(cur_group)

# main code form containers.py - diagnostics 

    
        
"""
8:36 14.05.2017
  1. Ќе считываютс€ некоторые переменные из определени€
  2. ƒублируютс€ три переменные с разными значени€ми
  3. Ќе все определени€ используютс€:
     # import_several_specs.py
     - считывать все вместе определени€
     - очередь определений + бить файл на сегменты
     - три причины разных определений (удобство, повторы, разный reader)
  4. Ќедостаточно контрольных значений
  5. ƒиагностика 
     - в виде print(), a не тестов
     - много текстовых фикстур
     - нужны простые контрольные сумму
  6. —истема каталогов может быть интегрирована с word2csv
  7. ѕисать версию csv в каталог


3:54 01.01.1970
- full testsuite

3:53 01.01.1970
- early check for duplicates
+ new emitter
- turn back to startswith 
- general flow in realease.py

Done:
sphinx-apidoc -F -M -f -o docs src/kep

Notes:
- may use class attributes as .attrib notation, but this is wtf
- why nosetests is used in PyCharm as default?


    # NEXT:
    # import_several_specs.py
    # Remove reader.py (leave todos/requirements + some code in 'main' in this module)
    # Compare pdef unique varname heads to Datapoints varname heads
    #     - Datapoints varname heads
    #     - pdef unique varname heads
    #     - print both
    #     - diff on list
    #     - find in file
    #     - decide why not imported +  fix specs? 
    #     - think of test
    # Pdef issues
    # More tabs issues
    # Guide to code review 

REQUIREMENTS
(1) release all values from d.emit('a') and test them against  *testpoints_valid* 
    *FIXME - fialing unittest
        kep\parser\test_containers.py F
         kep\parser\test_datapoints.py FFF
(2) control there are no varnames with same value and year/month/quarter 
    *DONE through emitter.HasValues
(3) make sure all labels from ParsingDefinition(specfile_path) are read, at least at some frequency 
    *DONE in Datapoints.not_imported()
(4) every variable from specs has a *testpoints_valid* 
    

REMEDIES
# - merge some specs to increase coverage - see what is total numer of headers
# - run headers check against each other - see if checks can work on different header
# - restore mechanism to apply parsing definitions to segments of file
# - add more elements to testpoints_valid 
"""   
