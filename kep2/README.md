Зачем все это
=============

Данные по инфляции в США я могу получить по ссылке <https://fred.stlouisfed.org/series/CPIAUCSL>
в виде ряда данных и через открытй API <https://research.stlouisfed.org/docs/api/fred/> и дальше анализирвать 
и отрисовывать эти данные в pandas или R.

Росстат предлагает изучать его [планы развития открытых данных](http://www.gks.ru/opendata/), покопаться в 
"витринах" данных ЕМИСС и полистать Наборы открытых данных Федеральной службы государственной статистики 
(это лучше, чем ничего), ряд данных по инфляции в России через открытый API мне никак не получить (напишите мне,
если это не так). Есть несколько сайтов с аналогичной статистикой в виде меню и файлов, но нет API 
для простого доступа к данным.

Основная задача этого проекта:
- наладить парсинг основной публикации Росстата "Краткосрочные экономические показатели" с проверкой 
  правильности данных 
- дать свободный доступ к этим рядам данных

После этого:
- выложить ряды данных со снятой сезонностью
- показать модели, которые можно строить с помощью этих данных
- связать данные Росстата из разных публикациями и данными ЦБ и других источников


Что делает этот конкретный модуль
=================================

Ежемесячный парсинг основной публикации Росстата "Краткосрочные экономические показатели" с проверкой 
правильности данных 

Сценарий работы модуля
======================
1. читаем исходные данные из CSV файла
2. читаем параметры парсинга
3. тащим итоговые данные из CSV файла с учетом парамтеров парсинга
   - в заданной частоте: годовые, квартальные или месячные данные
   - формат итоговых данных: \<имя переменной\> - \<год, квартал или месяц\> - \<значение\>
4. проверяем правильность при помощи контрольных значений

Комментарий к исходным данным и алгоритму
==========================================

Исходные данные в CSV файле были записаны из файлов Word (
делается [тут](https://github.com/epogrebnyak/data-rosstat-kep/tree/kep2/kep/word2csv)
и толко под Windows, сейчас не рассматриваем). В этом СSV файле, как правило, 
идет название таблицы, размерность, сама таблица, другая размерность, еще таблица и так далее.

Структура этих данных нечеткая:
- иногда название размерности указано в заголовке таблицы, иногда отдельным подзаголовком
- иногда заголовок задает группу показателей (например, "Налоги"), а подзаголовки - 
  конкретные показатели (такой налог или другой), для которых потом еще и меняется размерность
  (млрд. руб и % доходов бюджета всего).   
- всякие другие дикие случаи форматирования таблиц c примечаниями, объяснимые только внутренними соображениями 
  Росстата о прекрасном и нежной заботой о конечном пользователе (если серьезно - для печатной пуликации все
  отлично, для чтения данных - нет)
- от месяца к месяцу заголовки таблиц и их структра может немного или сильно поменяться

Исходя из кривизны данных были приняты решения:
- дампим файлы из Ворда в CSV, дальше разбираемся с файлом CSV 
- не строим иллюзий относительнос структурированности данных в этом CSV
- разбираем CSV строку за строкой, модифицируя привязку строк к названиям переменных 
- альтернатива - восстановить структуру документа в виде заголовок, подзаголовок, таблица данных,
  но есть ощущение, что это тупиковое решение - слишком кривая и нестабильная структура таблиц. 

Что еще выяснилось при реалзации:
- чтобы вытащить все переменные нужно разбивать CSV на сегменты и применять к сегментам 
  свои параметры парсинга.  

Ограничения
===========
- на данном этапе мы применяем только 
  
Куски сценария и модули программы  
==================================

1. исходные данные из CSV файла (csv_data.py))
---------------------------------
- CSV файл обернут классом ```CSV_Reader(path)``` в 
  [kep2.csv_data](https://github.com/epogrebnyak/data-rosstat-kep/blob/kep2/kep2/csv_data.py)
- строки файлы выплевываются методом ```.yield_dicts()``` в виде словарей с ключами _head, data, label_
- мы отошли от правила использовать ридер стандартной библиотеки ```csv```, так как файл кривой
  и желательно на более низком уровне понимать, что мы читаем  
  

2. параметры парсинга (parsing_defintions.py)
---------------------------------------------
- параметры парсинга сохранены в виде YAML файлов в директории [parsing_definitions](https://github.com/epogrebnyak/data-rosstat-kep/tree/kep2/kep2/parsing_definitions)
- история формата этих файлов такова - нужен простой способ привязать заголовки таблиц к названиям переменных и их размерности,
  генерировался закомментированный список заголовков, который вручную размечался как YAML файл.
- параметры парсинга загружаются из файла через класс ```ParsingDefinition(path)``` в 
  [parsing_defintions.py](https://github.com/epogrebnyak/data-rosstat-kep/blob/kep2/kep2/parsing_definitions.py)
- доступные аттрибуты: _headers, units, splitter_func_name_


3. генерируем итоговые данные (datapoints.py)
---------------------------------------------
- ```Datapoints(row_dicts, spec).emit(freq)``` генерирует итоговые данные (заменяет функцию входа```stream_by_freq()```)

**Основные шаги:**
- **label_rows()**:
 - просматриваем CSV на предмет заголовков из параметров парсинга
 - модифицируем название текущей переменной иcходя из привязки заголовков к названию переменной и размерности
 - считаем, текущая переменная из заголовка распространяется на ряды данных под заголовком
 - получаем привязку строк к названиям переменных  
- **get_datapoints()**: 
 - разбираем строки на годовые, квартальные и месячные данные
- **Datapoints().emit()**: 
 - возвращаем эти данные в формате \<имя переменной\> - \<год, квартал или месяц\> - \<значение\>
 
 Что поменялось в коде:
 - вынес метки в label.py
 - добавлены функции разбора ряда split*
 - добавлен более полный разбор значений в ячейке filter_value()
 
4. проверяем правильность (reader.py)
-------------------------------------
- проверку предлагается сделать скучным ручным способом - взять по одному значению из каждого ряда
  и проверить, если ли оно в итоговых данных, это надо сделать для годовых, месячных и квартальных данных
- сейчас проверка не срабатывает  в двух местах в начале файла мы получаем разные значения для однйо и той же переменной
  это происзодит из-за того, что по какой-то причине не перещелкивается размерность показателя.

```
    {'varname': 'IND_PROD_yoy', 'year': 2016, 'value': 101.3},
    {'varname': 'IND_PROD_yoy', 'year': 2016, 'value': 104.8},
```
	
```	
    {'varname': 'PROD_AGRO_MEAT_yoy', 'year': 2016, 'value': 103.4},
    {'varname': 'PROD_AGRO_MEAT_yoy', 'year': 2016, 'value': 30724.0},
    {'varname': 'PROD_AGRO_MEAT_yoy', 'year': 2016, 'value': 99.8},
```

Что надо сделать
================

**1 Куда-то продвигаться:**
- исправить ошибку дублирвания данных в reader.py (скорее всего устарел "__spec.txt")
- написать код проверки "не должно быть двух значений для одной точки"
- продвигаться дальше по строкам и добавлять новые контрольные значения для годовых пеерменных в reader.py 


**2 Обустраивать имеющийся код:**
- прокомментировать этот файл
- тестирование
  - восстановить имеющиеся закомментаированные тесты 
  - использовать Tempfile для тестов 
  - тесты из прошлой версии подтянуть
  - использовать py.test
- разные FIX и TODO 
- доработка структуры файлов, например:
 - вынести split* функции в отдельный модуль 

 
**3 Новая версия с сегментами:**
- нужен разбор CSV на сегменты, соотвествующие дополнительным определениям парсинга
- правильный выбор дополнительной фукнции разбора 
- писать для этого тесты


**4 Еще функции:**
 - получить название переменной по обозначению
 - получить размерность переменной по обозначению